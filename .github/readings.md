# READings

- Fast and slow if-statements: branch prediction in modern processors: <http://igoro.com/archive/fast-and-slow-if-statements-branch-prediction-in-modern-processors/>
- avrlibc `malloc` implementation details, checkout this page: <https://www.cs.ou.edu/~fagg/classes/general/atmel/avr-libc-user-manual-1.7.1.pdf>
- wikipedia, vector processor: <https://en.wikipedia.org/wiki/Vector_processor>
- CMU, Computer Architecture: SIMD/Vector/GPU, slide: <https://www.ece.cmu.edu/~ece740/f13/lib/exe/fetch.php%3Fmedia%3Dseth-740-fall13-module5.1-simd-vector-gpu.pdf>
- Berkeley course slide, CS252, Computer Architecture: Vector Processing, <https://people.eecs.berkeley.edu/~pattrsn/252S98/Lec06-vector.pdf>
- Stanford, ee382a, Vector Processors, <http://www.csit-sun.pub.ro/~cpop/Sisteme_cu_Microprocesoare_Avansate_SMPA/SMPA_curs_master5AAC/SMPA_curs5/EE382A/L14-vector%20processor.pdf>
- A Study of Productivity and Performance of Modern Vector Processors: <https://sharepoint.ecampus.rwth-aachen.de/units/rz/HPC/public/Shared%20Documents/BA_Springer_ModernVectorProcessors_2012-03.pdf>
- Mater thesis, Vector Processing as a Soft-CPU Accelerator: <https://www.ece.ubc.ca/~lemieux/publications/yu-masc2008.pdf>
- Stream processor architecture: <https://pdfs.semanticscholar.org/73fd/6b62330765ed8dac42d02995f248e4703450.pdf>
- Programmable stream processors: <http://cva.stanford.edu/publications/2003/ieeecomputer_stream.pdf>
- The Imagine Stream Architecture: <http://cva.stanford.edu/projects/imagine/project/im_arch.html>
- Stream Processors and GPUs: Architectures for High Performance Computing: <http://sokryk.tripod.com/Stream_Processors_and_GPUs_-_Architectures_for_High_Performance_Computing.pdf>
- Stream processing, <https://en.wikipedia.org/wiki/Stream_processing>
- SIMD Optimization Tips:
  - Programming Optimization tips: <http://www.azillionmonkeys.com/qed/optimize.html>
  - X86 asm optimization tips: <http://www.azillionmonkeys.com/qed/asm.html>
  - Pentium Optimizations: <http://www.azillionmonkeys.com/qed/p5opt.html>
  - SIMD Assembly Optimization: <https://blog.grijjy.com/2017/07/10/simd-assembly-optimization/>
  - Assembly Optimization Tips: <http://mark.masmcode.com/>
  - PERFORMANCE OPTIMIZATION ON MODERN PROCESSOR ARCHITECTURE THROUGH VECTORIZATION: <https://objectcomputing.com/resources/publications/sett/december-2016-performance-optimization-on-modern-processor-architecture-through-vectorization>
  - SIMD Programming: <https://www.moreno.marzolla.name/teaching/high-performance-computing/2017-2018/L08-SIMD.pdf>
  - PPoPP 2018, WPMVP 2018 Workshop on Programming Models for SIMD/Vector Processing, <https://ppopp18.sigplan.org/track/WPMVP2018>
  - A Data Layout Transformation for Vectorizing Compilers: <https://graphics.cg.uni-saarland.de/papers/perard-2018-wpmvp.pdf>
  - Intel MKL Library, Understanding Memory Formats, data layout: <https://oneapi-src.github.io/oneDNN/understanding_memory_formats.html>
  - A Compiler Approach for Exploiting Partial SIMD Parallelism, <https://dl.acm.org/citation.cfm?id=2886101>
  - Optimizations of the Whole Function Vectorization Based on SIMD Characteristics: <https://www.researchgate.net/publication/320230290_Optimizations_of_the_Whole_Function_Vectorization_Based_on_SIMD_Characteristics>
  - Look-ahead SLP: auto-vectorization in the presence of commutative operations: <https://www.researchgate.net/publication/323507137_Look-ahead_SLP_auto-vectorization_in_the_presence_of_commutative_operations> and its slide: <http://llvm.org/devmtg/2018-04/slides/Rocha-Look-Ahead%20SLP.pdf>
  - Automatic Parallelization of Programming Languages: Past, Present and Future, <https://www.microsoft.com/en-us/research/wp-content/uploads/2010/05/IWMSE-keynote.pdf>
  - The Tao of Parallelism in Algorithms: <http://www.cs.utexas.edu/~pingali/CS380C/2016-fall/papers/p12-pingali.pdf>
  - polly: a llvm framework for high level loop and data locality optimizations, <http://polly.llvm.org/> and its slide:<https://llvm.org/devmtg/2016-03/Tutorials/applied-polyhedral-compilation.pdf> and thesis: <https://polly.llvm.org/publications/grosser-diploma-thesis.pdf>
  - High Level Transforms for SIMD and Low-Level Computer Vision Algorithms, <https://hal.inria.fr/hal-01094906> and its slide, <http://tesson.julien.free.fr/LaMHA/2015/Lacassagne_LaMHA_2015-11-26.pdf>
- kernel fusion: <https://www.msra.cn/zh-cn/news/features/kernel-fusion-20170925>
- Hack the virtual memory: <https://blog.holbertonschool.com/hack-the-virtual-memory-c-strings-proc/>
- A tiny x86 boot-loader: <http://joebergeron.io/posts/post_two.html>
- Book reading: Small memory software tricks: <http://smallmemory.com/> and pdf see [here](https://www.researchgate.net/publication/220694739_Small_memory_software_patterns_for_systems_with_limited_memory) or [here](https://gamehacking.org/faqs/Small_Memory_Software.pdf)
- X64 cheat sheet: <https://cs.brown.edu/courses/cs033/docs/guides/x64_cheatsheet.pdf> and <http://pages.cs.wisc.edu/~remzi/Classes/354/Fall2012/Handouts/Handout-x86-cheat-sheet.pdf> and <http://www.scadahackr.com/library/Documents/Cheat_Sheets/Programming%20-%20x86%20Instructions%201.pdf>
- LLVM FPGA: <https://llvm.org/devmtg/2014-10/Slides/Baker-CustomHardwareStateMachines.pdf>
- NUMA, checkout this page: <http://cenalulu.github.io/linux/numa/>
- Intel Haswell arch, see wiki page: <https://en.wikipedia.org/wiki/Haswell_(microarchitecture)>
- Intel Xeon Phi(MIC) and GPU: <https://www.lrz.de/services/compute/courses/x_lecturenotes/MIC_GPU_Workshop/MIC-AND-GPU-2015.pdf>
- Introduction to Parallel Algorithms and Parallel Program Design, checkout this slide: <http://ipcc.cs.uoregon.edu/lectures/lecture-12-algorithms.pdf>
- OpenARC: Open Accelerator Research Compiler, <https://ft.ornl.gov/research/openarc> and related publications: <https://ft.ornl.gov/publications>
- Source Cetus: Source-to-source Compiler source Compiler Infrastructure for Multicores, checkout this slide: <https://engineering.purdue.edu/Cetus/Documentation/tutorials/ppopp09.pdf> and <https://engineering.purdue.edu/Cetus/>
- ROSE compiler: source to source program transformation and analysis tools by Lawrence Livermore National Laboratory: <http://rosecompiler.org/> & <https://github.com/rose-compiler/rose/wiki/Publications>
- Clacc: OpenACC Support for Clang/LLVM, <http://llvm.org/devmtg/2018-04/slides/Vetter-Clacc.pdf>
- OpenMP in clang, <https://clang-omp.github.io/> and its github repo: <https://github.com/llvm-project/openmp> and tutorial: <https://www.openmp.org/wp-content/uploads/omp-hands-on-SC08.pdf>
- Introduction to GCC Inline Asm: <http://asm.sourceforge.net/articles/rmiyagi-inline-asm.txt>
- A Tiny Guide to GCC Inline Assembly: <http://ericw.ca/notes/a-tiny-guide-to-gcc-inline-assembly.html> and this tutorial: <https://www.cs.virginia.edu/~clc5q/gcc-inline-asm.pdf>
- X86 Assembly Guide: <http://www.cs.virginia.edu/~evans/cs216/guides/x86.html>
- asm inline testcases in clang: <https://github.com/llvm-mirror/clang/blob/master/test/CodeGen/asm.c>
- heap vs stack, <https://www.gribblelab.org/CBootCamp/7_Memory_Stack_vs_Heap.html>
- MMU, Memory management unit, <https://en.wikipedia.org/wiki/Memory_management_unit>
- Hardware memory models: x86-TSO, <https://www.cs.rice.edu/~johnmc/comp522/lecture-notes/COMP522-2019-Lecture9-HW-MM.pdf>
- Linux Package Managers: <https://en.wikipedia.org/wiki/Package_manager>
- Applying Temporal Blocking with a Directive‐based Approach, <https://llvm-hpc4-workshop.github.io/slides/Endo.pdf>
- Improving Compiler Optimizations using Program Annotations, <https://sisl.rites.uic.edu/static/pics/thesis-2.pdf>
- Towards Automatic HBM Allocation using LLVM: A Case Study with Knights Landing, <https://www.computer.org/csdl/proceedings/llvm-hpc/2016/3878/00/07839456.pdf>
- Locality Aware Memory Assignment and Tiling, [acm](http://delivery.acm.org/10.1145/3200000/3196070/a130-rogers.pdf?ip=202.175.167.104&id=3196070&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E896D0D4959F561C0%2E6D218144511F3437&__acm__=1530546026_dcc8e8cdae435257aae5419cc797b717)
- Design Pattern, <http://www.vincehuston.org/dp/>
- cpp, a non const reference cannot bind to a temporary object, <https://stackoverflow.com/questions/1565600/how-come-a-non-const-reference-cannot-bind-to-a-temporary-object>
- A collection of pure bash alternatives to external processes: <https://github.com/dylanaraps/pure-bash-bible>
- Build you own x: <https://github.com/danistefanovic/build-your-own-x>
- Inline asm macro expr format: <https://stackoverflow.com/questions/37146962/macro-with-inline-asm-in-c-is-having-formatting-problems>
- Macro function overloading: <https://stackoverflow.com/questions/11761703/overloading-macro-on-number-of-arguments>
- Clang optimization levels: <https://stackoverflow.com/questions/15548023/clang-optimization-levels/15548189#15548189> and this post:<https://nval.andreasherten.de/2016/08/18/clang-optimization-levels.html>
- const_cast in c++: <https://stackoverflow.com/questions/19554841/how-to-use-const-cast> and <https://docs.microsoft.com/en-us/cpp/cpp/const-cast-operator?view=vs-2017>
- Clang Optimization for Embedded Linux: <http://events17.linuxfoundation.org/sites/events/files/slides/GCC%252FClang%20Optimizations%20for%20Embedded%20Linux.pdf>
- C++ Template Instantiation and Concepts in Clang, impl details checkout this [paper](https://pdfs.semanticscholar.org/aef3/f3c2ada21aea2bf7805e2c221c85ca88d506.pdf)
- Architecture of Clang, checkout this paper: <http://wiki.ifs.hsr.ch/SemProgAnTr/files/Clang_Architecture_-_ChristopherGuntli.pdf> and this slide: <https://llvm.org/devmtg/2017-06/2-Hal-Finkel-LLVM-2017.pdf>
- Clang AST tool for cpp, checkout this paper: <https://people.cs.clemson.edu/~malloy/publications/papers/2014/acmse2014.pdf>
- The Store-Load Address Table and Speculative Register Promotion, <http://aggregate.org/LAR/p235-postiff.pdf>
- Register Promotion by Sparse Partial Redundancy Elimination of Loads and Stores, <http://theory.stanford.edu/~robert/papers/rvi.ps>
- Speculative Register Promotion Using Advanced Load Address Table (ALAT), checkout this [paper](https://www-users.cs.umn.edu/~jin/cgo03.pdf)
- Register Promotion in C Programs, <https://www.researchgate.net/profile/Keith_Cooper2/publication/2804738_Register_Promotion_in_C_Programs/links/568d708e08aead3f42eda21c/Register-Promotion-in-C-Programs.pdf>
- Controlling Virtual Register Pressure in LLVM Middle-End, checkout this slide: <https://llvm.org/devmtg/2014-10/Slides/Baev-Controlling_VRP.pdf>
- loop fusion and tiling, see this slide: <https://www.cs.indiana.edu/~achauhan/Teaching/B629/2010-Fall/StudentPresns/LoopFusionTiling.pdf>
- Loop Fusion Amid Complex Control Flow: <https://llvm.org/devmtg/2015-04/slides/LLVMEuro2015LoopFusionAmidComplexControlFlow.pdf>
- A Proposal for Loop-Transformation Pragmas, <https://arxiv.org/pdf/1805.03374.pdf>
- Loop transformation in LLVM: <https://users.eecs.northwestern.edu/~simonec/Simone%20Campanoni_files/Teaching/CAT/slides/loop_CATs.pdf>
- A Novel Instruction Scratchpad Memory Optimization Method based on Concomitance Metric, checkout this slide: <http://www.aspdac.com/aspdac2006/archives/pdf/6B-5.pdf>
- MiniMat: Matrix Language in OCaml LLVM, <http://www.cs.columbia.edu/~sedwards/classes/2016/4115-summer-cvn/reports/MiniMat.pdf>
- A Journey of OpenCL 2.0 Development in Clang, <https://llvm.org/devmtg/2016-03/Presentations/AnastasiaStulova_OpenCL20_EuroLLVM2016.pdf>
- OpenCL with LLVM: <https://llvm.org/devmtg/2009-10/OpenCLWithLLVM.pdf>
- Open standards from Khronos for heterogeneous computing: Vulkan, SPIR-V & OpenCL SYCL, <http://www.gipsa-lab.grenoble-inp.fr/thematic-school/gpu2015/presentations/GIPSA-Lab-GPU2015-R-Keryell-01.pdf>
- International Workshop on Polyhedral Compilation Techniques(IMPACT'15), On Recovering Multi-Dimensional Arrays in Polly: <http://impact.gforge.inria.fr/impact2015/papers/impact2015-grosser.pdf> and its slide: <http://impact.gforge.inria.fr/impact2015/papers/impact2015-grosser-slides.pdf>
- Master Thesis: The Insieme Compiler Frontend: A Clang-based C/C++ Frontend, <http://insieme-compiler.org/pub/master_thesis_hoeckner.pdf>
- Tensor networks and machine learning: <http://kits.ucas.ac.cn/images/articles/2017/Machine_Learning/conference/MilesStoudenmire.pdf> and <http://users.cecs.anu.edu.au/~koniusz/tensors-cvpr17/present/oseledets_ivan_tmcv2017.pdf>
- Tensor networks and deep learning, checkout this slide: <http://users.cecs.anu.edu.au/~koniusz/tensors-cvpr17/present/cichocki_andrzej_tmcv2017.pdf>
- A. Einstein, The Foundation of the Generalised Theory of Relativity, Section B about `Tensor`: <https://en.wikisource.org/wiki/The_Foundation_of_the_Generalised_Theory_of_Relativity>
- Tensor history: <https://en.wikipedia.org/wiki/Tensor#History>
- Vector field: <https://en.wikipedia.org/wiki/Vector_field>
- de Bruijn index in mathematical logic: <https://en.wikipedia.org/wiki/De_Bruijn_index>
- Compiler rewriting system: Quick Introduction to Term Rewriting, <http://www.meta-environment.org/doc/books/extraction-transformation/term-rewriting/term-rewriting.html>
- CS230, CNN cheatsheet: <http://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks>
- Image convolution understanding via OpenCV and Python: <https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/>
- Accelerator Compiler for the VENICE Vector Processor[.](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/37671.pdf)
- loop idioms: [Mining Semantic Loop Idioms](http://web.cs.ucdavis.edu/~devanbu/tse-coils-paper.pdf)
- Compiler-assisted Performance Analysis: <https://llvm.org/devmtg/2016-11/Slides/Nemet-Compiler-assistedPerformanceAnalysis.pdf>
- trace the impl of eigen tensor: <https://github.com/eigenteam/eigen-git-mirror/tree/master/unsupported/Eigen/CXX11/src/Tensor>
  - lazy evaluation & design pattern
- tensor contraction: <http://my.math.wsu.edu/help/maple/tensorLLcontractI.html> and <https://en.wikipedia.org/wiki/Tensor_contraction> and <https://physics.stackexchange.com/questions/175368/what-does-it-mean-to-contract-a-tensor-identity> and <https://www.maplesoft.com/support/help/maple/view.aspx?path=DifferentialGeometry/Tensor/ContractIndices>
- Swift compiler repo: <https://github.com/apple/swift>
- A Brief Overview of Swift Compiler: <https://medium.com/xcblog/a-brief-overview-of-swift-compiler-7af0bd684718>
- Technical report, Armadillo: An Open Source C++ Linear Algebra Library[.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.385.4911&rep=rep1&type=pdf)
- CodeProject, A generic, reusable, and extendable matrix class[.](https://www.codeproject.com/Articles/3613/A-generic-reusable-and-extendable-matrix-class)
- Book reading: Intel Threading Building Blocks OutFitting C++ for Multi-Core Processor Parallelism[.](http://index-of.es/Programming/C++/O'Reilly%20Intel%20Threading%20Building%20Blocks%20OutFitting%20C++%20for%20Multi-Core%20Processor%20Parallelism.pdf)
- Tensor Come of Age, Why the AI revolution will help HPC: <https://arxiv.org/pdf/1709.09108.pdf>
- Alignment in C: Seminar “Effiziente Programmierung in C” <https://wr.informatik.uni-hamburg.de/_media/teaching/wintersemester_2013_2014/epc-14-haase-svenhendrik-alignmentinc-paper.pdf>
- Compiler bootstrapping: <https://en.wikipedia.org/wiki/Bootstrapping_(compilers)>
- An in-depth look at Google’s first Tensor Processing Unit (TPU): <https://cloud.google.com/blog/products/gcp/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu>
- What makes TPUs fine-tuned for deep learning? <https://cloud.google.com/blog/products/ai-machine-learning/what-makes-tpus-fine-tuned-for-deep-learning>
- Expression Template Vectorization: <https://arxiv.org/pdf/1109.1264.pdf> and <https://uni.edu/ajur/v10n4/Progsch%20et%20al%20pp%201-10.pdf>
- book reading, Modern C++ Design: Generic Programming and Design Patterns Applied[.](https://www.mimuw.edu.pl/~mrp/cpp/SecretCPP/Addison-Wesley%20-%20Modern%20C++%20Design.%20Generic%20Programming%20and%20Design%20Patterns%20Applied.pdf)
- CRTP, Curiously Recurring Template Pattern: <https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern> and <https://3aec1b23-a-eadc3f87-s-sites.googlegroups.com/a/gertrudandcope.com/info/Publications/InheritedTemplate.pdf?attachauth=ANoY7cr9fcwxMyKM5ODngV9meEW6xkI1EXOuLnchY9hVjWJyyZYsX8y1rM7BJ7i3_COFNGHlkANyXma4OoWjF8cqVOJHWcqReNPCESEO5HQSmqPZkeSJr_Im3aWl516M-mlet2R9NdKvslJxpWIbI9myoArJqelMQcQb16ZZuaUk9RbsPH4Rg8LjMD2eC6TZKGWSiPPTeOF4uKrQsiCJutEArefOETxGgYFFy0HzDAXY8M_MUpQ1UzA%3D&attredirects=0>
- The Curiously Recurring Template Pattern in C++[.](https://eli.thegreenplace.net/2011/05/17/the-curiously-recurring-template-pattern-in-c)
- Loop Unrolling over Template Arguments: <https://www.codeproject.com/articles/75423/loop-unrolling-over-template-arguments>
- Stream Vector Processing Unit: Stream Processing Using SIMD on a General Purpose Processor [.](http://www.owlnet.rice.edu/~elec525/projects/stream_report.pdf)
- Parallel Expression Template for Large Vectors [.](https://hal.archives-ouvertes.fr/hal-00551682/document)
- Advanced expression templates programming[.](http://www.sci.utah.edu/~wolters/PaperWolters/2010/HaerdtleinEtAl_CompVisSci_2010.pdf)
- CUDA 10 Features Revealed: Turing, CUDA Graphs, and More. <https://devblogs.nvidia.com/cuda-10-features-revealed/> and NVIDIA Turing GPU Architecture: <https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf>
- Building a cpp reflection system using clang and llvm: <https://github.com/CppCon/CppCon2018/blob/master/Presentations/building_a_cpp_reflection_system_in_one_weekend_using_clang_and_llvm/building_a_cpp_reflection_system_in_one_weekend_using_clang_and_llvm__arvid_gerstmann__cppcon_2018.pdf>
- gcc vector_size attr: <https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html>
- TABLA: A Unified Template-based Framework for Accelerating Statistical Machine Learning[.](https://www.cc.gatech.edu/~hadi/doc/paper/2015-tr-tabla.pdf)
- PLDI'18, Polyhedral Auto-transformation with No Integer Linear Programming[.](https://pldi18.sigplan.org/event/pldi-2018-papers-polyhedral-auto-transformation-with-no-integer-linear-programming)
- PLDI'18, Spatial: A Language and Compiler for Application Accelerators[.](http://csl.stanford.edu/~christos/publications/2018.spatial.pldi.pdf)
- PLDI'18, SWOOP: Software-Hardware Co-design for Non-speculative, Execute-Ahead, In-Order Cores[.](http://www.sjalander.com/research/pdf/sjalander-pldi2018.pdf)
- Tensor software: <https://en.wikipedia.org/wiki/Tensor_software>
- An Incremental Approach to Compiler Construction[.](http://scheme2006.cs.uchicago.edu/11-ghuloum.pdf)
- Optimizing Parallel Reduction in CUDA: <https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf>
- JIT native code generation for TensorFlow computation graphs using Python and LLVM: <http://blog.christianperone.com/2016/08/jit-native-code-generation-for-tensorflow-computation-graphs-using-python-and-llvm/>
- Optimizing Large Matrix-Vector Multiplications[.](https://simulationcorner.net/index.php?page=fastmatrixvector)
- GPGPU benchmark shoc: SpMV example, <https://github.com/vetter/shoc/tree/master/src/cuda/level1/spmv> and its wiki page: <https://github.com/vetter/shoc/wiki>
- Matrix market text file format: <https://math.nist.gov/MatrixMarket/formats.html> and ANSI C API for mm I/O: <https://math.nist.gov/MatrixMarket/mmio-c.html>
- Roofline Model, wiki page: <https://en.wikipedia.org/wiki/Roofline_model>
- DeepSmith, Compiler Fuzzing through Deep Learning: <http://homepages.inf.ed.ac.uk/hleather/publications/2018_deepfuzzing_issta.pdf>
- slide, Hardware acceleration for machine learning and big data analytics[.](https://www.ee.columbia.edu/~cylin/course/bigdata/EECS6895-AdvancedBigDataAnalytics-Lecture10.pdf)
- Compiler Optimization, loop unswitching: <https://en.wikipedia.org/wiki/Loop_unswitching>
- Vector LLVA: A Virtual Vector Instruction Set for Media Processing[.](https://www.usenix.org/legacy/events/vee06/full_papers/p46-bocchino.pdf)
- What Every Computer Scientist Should Know About Floating-Point Arithmetic[.](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)
- How to align a pointer in C, see stack overflow[.](https://stackoverflow.com/questions/4840410/how-to-align-a-pointer-in-c)
- Distributed Deep learning training: <https://blog.skymind.ai/distributed-deep-learning-part-1-an-introduction-to-distributed-training-of-neural-networks/>
- LINM (Loop Invariant Node Motion) optimization pass in Graph Optimization for Tensorflow, commited by Alibaba PAI-Blade team, checkout here: <https://github.com/tensorflow/tensorflow/pull/16306> and Bringing TVM into TensorFlow for Optimizing Neural Machine Translation on GPU, checkout TVM blog: <https://tvm.ai/2018/03/23/nmt-transformer-optimize.html>
- Add a new backend to TVM: <https://discuss.tvm.ai/t/nnvm-is-there-any-guide-to-add-a-new-backend/459/4>
- How CUDA kernel is launched in TVM stack: <https://discuss.tvm.apache.org/t/how-cuda-kernel-is-launched-in-tvm-stack/6167/3>
- Automatic Optimization of the Computation Graph in the Nengo Neural Network Simulator[.](https://www.frontiersin.org/articles/10.3389/fninf.2017.00033/full)
- Topological Sort Algorithm: <https://courses.cs.washington.edu/courses/cse326/03wi/lectures/RaoLect20.pdf>
- Computation graph auto-diff: <http://www.cs.cornell.edu/courses/cs5740/2017sp/lectures/04-nn-compgraph.pdf>
- Calculus on Computational Graphs: Backpropagation, <https://colah.github.io/posts/2015-08-Backprop/>
- Understanding Graphs, Automatic Differentiation and Autograd: <https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/>
- PyTorch AUTOGRAD MECHANICS: <https://pytorch.org/docs/stable/notes/autograd.html> and Apache Singa autograd: <http://singa.apache.org/docs/autograd>
- Continuation in PL: <https://en.wikipedia.org/wiki/Continuation>
- Stanford CS217: Hardware Accelerators for Machine Learning <https://cs217.stanford.edu>
- Notes on Programming Standard ML of New Jersey: <http://www.cs.cornell.edu/riccardo/prog-smlnj/notes-011001.pdf> and basic polymorphic typechecking: <https://www.classes.cs.uchicago.edu/archive/2016/fall/22600-1/docs/polymorphism.pdf>
- Building A C Compiler Type System: <http://blog.robertelder.org/building-a-c-compiler-type-system-the-formidable-declarator/>
- Graph coloring problem slide: <http://www.sci.brooklyn.cuny.edu/~amotz/GC-ALGORITHMS/PRESENTATIONS/coloring.pdf>
- LLVM simple MachineInstr-level dead-code-elimination pass: <http://web.mit.edu/freebsd/head/contrib/llvm/lib/CodeGen/DeadMachineInstructionElim.cpp> and <https://blog.quarkslab.com/global-dead-code-elimination-for-llvm-revisited.html>
- LCPC'05, Revisiting graph coloring register allocation: a study of the chaitin-briggs and callahan-koblenz algorithms, <https://llvm.org/pubs/2005-10-20-LCPC-RegAlloc.pdf>
- LLVM Matrix supporting: <http://lists.llvm.org/pipermail/llvm-dev/2018-December/128322.html>
- TVM 0.5 release note: <https://github.com/dmlc/tvm/issues/2448>
- Vertex coloring: Welsh–Powell Algorithm, <http://mrsleblancsmath.pbworks.com/w/file/fetch/46119304/vertex%20coloring%20algorithm.pdf>
- Internal and External Linkage in C++: <http://www.goldsborough.me/c/c++/linker/2016/03/30/19-34-25-internal_and_external_linkage_in_c++/>
- Program and Linkage in C++: <https://docs.microsoft.com/en-us/cpp/cpp/program-and-linkage-cpp?view=vs-2017>
- Extern linkage for const globals, non-const globals and constexpr linkage: <https://docs.microsoft.com/en-us/cpp/cpp/extern-cpp?view=vs-2017>
- static initialization order ‘fiasco’ (problem): <https://isocpp.org/wiki/faq/ctors#static-init-order>
- Python 2 and 3: <http://python3porting.com/noconv.html>
- Functional thinking: <https://www.ibm.com/developerworks/views/java/libraryview.jsp?search_by=functional+thinking>
- Python Functional Programming HOWTO: <https://docs.python.org/3.7/howto/functional.html>
- CC'16, SVF: Interprocedural Static Value-Flow Analysis in LLVM: <https://yuleisui.github.io/publications/cc16.pdf> and LLVM devmtg slide: <https://llvm.org/devmtg/2016-03/Presentations/SVF_EUROLLVM2016.pdf>
- Getting to Go, ISMM'18, GC's view of Go by Google: <https://blog.golang.org/ismmkeynote>
- PLDI'18 session: <https://pldi18.sigplan.org/program/program-pldi-2018>
- Workshop @ PLDI'18, Machine Learning and Programming Languages (MAPL): <https://pldi18.sigplan.org/track/mapl-2018-papers#program>
- Workshop @ CGO'19, Compilers for Machine Learning, <https://www.c4ml.org>
- Hierarchical Data Format: <https://en.wikipedia.org/wiki/Hierarchical_Data_Format>
- Python Memoization with Decorators: <https://www.python-course.eu/python3_decorators.php> and <https://www.python-course.eu/python3_memoization.php>
- Python dict impl: <https://www.laurentluce.com/posts/python-dictionary-implementation/>
- Python Coroutines and Tasks: <https://docs.python.org/3/library/asyncio-task.html>
- glibc qsort implementation: <https://code.woboq.org/userspace/glibc/stdlib/qsort.c.html>
- glibc stdlib source code: <https://code.woboq.org/userspace/glibc/stdlib/>
- IBM cell processor: <http://meseec.ce.rit.edu/756-projects/spring2006/d2/6/cell-architecture-final.pdf>
- SPM-based manycore example, rexcomputing: <http://rexcomputing.com>
- Term, thrashing: <https://en.wikipedia.org/wiki/Thrashing_(computer_science)>
- ISCA'18, Generic System Calls for GPUs, UVM and cache coherence ease programmability: <https://iscaconf.org/isca2018/slides/9B4.pdf> and github repo: <https://github.com/RadeonOpenCompute/ROCT_syscall>
- ASPLOS'19, pLock: A Fast Lock for Sunway Taihulight: <http://alchem.usc.edu/portal/static/download/swlock.pdf>
- Literal pool in ARM: <http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0473h/Bgbccbdi.html> and <http://benno.id.au/blog/2009/01/02/literal-pools>
- Sockets vs. RDMA Interface over 10-Gigabit Networks: An In-depth Analysis of the Memory Traffic Bottleneck: <http://mvapich.cse.ohio-state.edu/static/media/publications/slide/balaji_10gige.pdf>
- TVM and XLA/HLO: <https://github.com/dmlc/tvm/issues/151>
- XLA and Polyhedral Compilation through LLVM Polly: <https://github.com/tensorflow/tensorflow/issues/8100>
- DON’T UNROLL ADJOINT: DIFFERENTIATING SSA-FORM PROGRAMS: <https://arxiv.org/pdf/1810.07951.pdf>
- DLVM: A MODERN COMPILER INFRASTRUCTURE FOR DEEP LEARNING SYSTEMS: <https://arxiv.org/pdf/1711.03016.pdf>
- TVM Relay IR, rfc: <https://github.com/dmlc/tvm/pull/1672> and issue: <https://github.com/dmlc/tvm/issues/1673>
- TVM Relay: <https://docs.tvm.ai/langref/index.html>
- TVM Relay ANTLR grammar: <https://github.com/dmlc/tvm/blob/master/python/tvm/relay/grammar/Relay.g4>
- TVM Relay C++ front-end plan: <https://github.com/dmlc/tvm/issues/2685>
- TVM discussion about Google's MLIR: <https://discuss.tvm.ai/t/google-lasted-work-mlir-primer/1721> and the discussion @zhihu: <https://www.zhihu.com/question/319145946/answer/647107250>
- Choice about IR, SSA or ANF? <https://discuss.tvm.ai/t/choice-about-ir-ssa-or-anf/1757>
- Automatic Differentiation in Machine Learning: a Survey: <https://arxiv.org/pdf/1502.05767.pdf>
- Announcing TensorFlow Fold: Deep Learning With `Dynamic Computation Graphs`: <https://ai.googleblog.com/2017/02/announcing-tensorflow-fold-deep.html> and ICLR'17, Deep Learning with Dynamic Computation Graphs: <https://arxiv.org/pdf/1702.02181.pdf>
- TensorFlow Grappler optimizations: <https://web.stanford.edu/class/cs245/slides/TFGraphOptimizationsStanford.pdf>
- A Survey on Compiler Autotuning using Machine Learning: <https://arxiv.org/pdf/1801.04405.pdf>
- Zheng Wang, Machine Learning in Compiler Optimisation: <https://arxiv.org/pdf/1805.03441.pdf>
- Jeff Dean, Machine Learning for Systems and Systems for Machine Learning: <http://learningsys.org/nips17/assets/slides/dean-nips17.pdf>
- NIPS'16, deep learning jit opt, Knet: beginning deep learning with 100 lines of Julia, <http://www2.denizyuret.com/bib/yuret/yuret2016knet/knet-beginning-deep%20(3).pdf>
- EuroLLVM'19, by Chris Lattner, MLIR: Multi-Level Intermediate Representation for Compiler Infrastructure: <https://www.youtube.com/watch?v=qzljG6DKgic>
- EuroLLVM'19, Tutorial: Building a Compiler with MLIR: <http://www.llvm.org/devmtg/2019-04/slides/Tutorial-AminiVasilacheZinenko-MLIR.pdf> 
- MLIR arXiv publication: <https://arxiv.org/pdf/2002.11054.pdf>
- EuroLLVM'19, by Thomas Joerg, Automated GPU Kernel Fusion with XLA: <http://www.llvm.org/devmtg/2019-04/slides/TechTalk-Joerg-Automated_GPU_Kernel_Fusion_with_XLA.pdf>
- EuroLLVM'19, Just compile it: High-level programming on the GPU with Julia: <http://www.llvm.org/devmtg/2019-04/slides/TechTalk-Besard-Just_compile_it_high_level_programming_on_the_GPU_with_Julia.pdf>
- EuroLLVM'19, Building an LLVM-based tool: lessons learned: <http://www.llvm.org/devmtg/2019-04/slides/Tutorial-Denisov-Building_an_LLVM_based_tool.pdf>
- EuroLLVM'19, Loop Fusion, Loop Distribution and their Place in the Loop Optimization Pipeline: <http://www.llvm.org/devmtg/2019-04/slides/TechTalk-Barton-Loop_fusion_loop_distribution_and_their_place_in_the_loop_optimization_pipeline.pdf>
- EECC756, Systolic Architectures: <http://web.cecs.pdx.edu/~mperkows/temp/May22/0020.Matrix-multiplication-systolic.pdf>
- PLDI'19 @ ARRAY'19: TeIL: a type-safe imperative Tensor Intermediate Language, <https://pldi19.sigplan.org/details/ARRAY-2019-papers/2/TeIL-a-type-safe-imperative-Tensor-Intermediate-Language>
- PLDI'19 @ ARRAY'19: <https://pldi19.sigplan.org/home/ARRAY-2019#event-overview>
- PLDI'19: SA-SPM: An Efficient Compiler for Security Aware Scratchpad Memory (Invited)[.](https://conf.researchr.org/details/LCTES-2019/LCTES-2019-papers/16/SA-SPM-An-Efficient-Compiler-for-Security-Aware-Scratchpad-Memory-Invited-)
- PLDI'19: Microsoft Research, India, Compiling KB-Sized Machine Learning Models to Tiny IoT Devices[.](https://www.microsoft.com/en-us/research/uploads/prod/2018/10/paper.pdf)
- PLDI'18 @ ARRAY'18: Inner Array Inlining for Structure of Arrays Layout
- Euromicro International Conference on Parallel, Distributed, and Network-Based Processing'13: Impact of Data Structure Layout on Performance[.](http://www4.di.uminho.pt/~jls/pdp2013pub.pdf)
- Domain Driven Design, DDD Quickly: <http://www.carfield.com.hk/document/software+design/dddquickly.pdf>
- Integrating NVIDIA Deep Learning Accelerator (NVDLA) with RISC-V SoC on FireSim: <https://arxiv.org/pdf/1903.06495.pdf>
- Why Google Stores Billions of Lines of Code in a Single Repository: <https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext>
- ARRAY'14, NOVA: A Functional Language for Data Parallelism: <https://dl.acm.org/citation.cfm?id=2627375>
- How to Use Performance Monitor Unit(PMU) of 64-bit ARMv8-A in Linux: <http://zhiyisun.github.io/2016/03/02/How-to-Use-Performance-Monitor-Unit-(PMU)-of-64-bit-ARMv8-A-in-Linux.html>
- A very interesting work for Scenario Specification and Scene Generation @PLDI'19: Scenic: A Language for Scenario Specification and Scene Generation: <https://math.berkeley.edu/~dfremont/papers/PLDI19.pdf> and <https://arxiv.org/pdf/1809.09310.pdf>
- Nice community: Haifa Linux Users Group: <http://haifux.org>
- Meta-programming and reflection: <https://stackoverflow.com/questions/7641881/is-metaprogramming-a-subset-of-reflection>
- Franco Barbanera, Short Introduction to Functional Programming and Lambda-calculus: <http://www.dmi.unict.it/~barba/FOND-LING-PROG-DISTR/PROGRAMMI-TESTI/READING-MATERIAL/ShortIntroFPprog-lang.htm> and <http://joycse06.github.io/blog/2016/07/intro-to-lambda-calculus-and-its-relation-to-functional-programming/>
- Lambda calculus: <https://cs242.stanford.edu/f18/lectures/01-2-lambda-calculus.html>
- Future Directions for Optimizing Compilers: <https://arxiv.org/pdf/1809.02161.pdf>
- Book reading: `APL` is widely recognized as one of the  first array languages. It is inspired by mathematical notation and relies heavily on collective operations. APL is interpreted, thus it naturally allows for dynamic checkings. See book writen by John Wiley and et al at year 1962, A Programming Language: <http://www.softwarepreservation.org/projects/apl/Books/APROGRAMMING%20LANGUAGE>
- Nice book: Syntax and Semantics of Programming Languages: <http://www.divms.uiowa.edu/~slonnegr/plf/Book/>
- A Comprehensive Introduction to Different Types of Convolutions in Deep Learning: <https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215> and Tensor Transpose: <https://arxiv.org/abs/1411.1503>
- TensorFlow add new op: <https://www.tensorflow.org/guide/extend/op>
- C++ move semantics: <https://bulldogjob.com/articles/885-c-frequently-failed-interview-question> and 10 Proven C++ Programming Questions to Ask on Interview: <https://tests4geeks.com/cpp-interview-questions/>
- Automatic Checking of the Usage of the C++11 Move Semantics: <https://pdfs.semanticscholar.org/226f/bce5dcd6d8ced30c253204342bbbfa246092.pdf>
- Imperative programming: <https://en.wikipedia.org/wiki/Imperative_programming> and Declarative programming: <https://en.wikipedia.org/wiki/Declarative_programming>
- Lua: <https://zh.wikipedia.org/wiki/Lua>
- Tensor Contrations Layers for Parsimonious Deep Nets: <https://ibug.doc.ic.ac.uk/media/uploads/documents/tensor_contraction_layers.pdf> and Role of Tensors in Deep Learning: <http://users.cecs.anu.edu.au/~koniusz/tensors-cvpr17/present/anandkumar_anima_tmcv2017.pdf>
- Inner product and outer product: <http://www.inf.ed.ac.uk/teaching/courses/cfcs1/lectures/cfcs_l10.pdf>
- History of compiler construction: <https://en.wikipedia.org/wiki/History_of_compiler_construction>
- Lectures on Constructive Functional Programming: <https://www.cs.ox.ac.uk/files/3390/PRG69.pdf>
- Effects of depth and width in DNN models: <https://stats.stackexchange.com/questions/214360/what-are-the-effects-of-depth-and-width-in-deep-neural-networks> and conclusion: wider residual networks allow many multiplications to be computed in parallel, whilst deeper residual networks use more sequential computations (since the computation depend on the previous layer).
- TVM GPU auto TensorCore CodeGen: <https://github.com/dmlc/tvm/issues/4105>
- Jetson AGX Xavier: Deep Learning Inference Benchmarks: <https://developer.nvidia.com/embedded/jetson-agx-xavier-dl-inference-benchmarks>
- NVIDIA Jetson AGX Xavier Delivers 32 TeraOps for New Era of AI in Robotics: <https://devblogs.nvidia.com/nvidia-jetson-agx-xavier-32-teraops-ai-robotics/>
- How we built a Super Nintendo out of a wireless keyboard @Sifteo #Sifteo: <https://blog.adafruit.com/2012/12/05/how-we-built-a-super-nintendo-out-of-a-wireless-keyboard-sifteo-sifteo/>
- How fast is my model?<https://machinethink.net/blog/how-fast-is-my-model/> & Memory usage and computational considerations: <http://imatge-upc.github.io/telecombcn-2016-dlcv/slides/D2L1-memory.pdf> and CS231n lecture 9: CNN architectures, <http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture09.pdf>
- A Gentle Introduction to Probabilistic Programming Languages: <https://towardsdatascience.com/a-gentle-introduction-to-probabilistic-programming-languages-ba9105d9cbce>
- ASPLOS'20: Interstellar: Using Halides Scheduling Language to Analyze DNN Accelerators, <https://asplos-conference.org/wp-content/uploads/2020/abstracts/paper_4_0.html>
- ASPLOS'20: AutoTM: Automatic Tensor Movement in Heterogeneous Memory Systems using Integer Linear Programming, <https://arch.cs.ucdavis.edu/papers/2019-12-15-autotm>
- ASPLOS'20: FlexTensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System, <https://asplos-conference.org/wp-content/uploads/2020/abstracts/paper_9_0.html>
- ASPLOS'20: Learning-based Memory Allocation for C++ Server Workloads, <http://www.cs.utexas.edu/users/mckinley/papers/llama-asplos-2020.pdf>
- depthwise convolution implementation details: <https://eli.thegreenplace.net/2018/depthwise-separable-convolutions-for-machine-learning/>
- Batch Inference vs Online Inference in Production: <https://mlinproduction.com/batch-inference-vs-online-inference/>
- Lift project successor with MLIR support: <https://github.com/rise-lang>
- Symbolic Execution: <https://www.cs.umd.edu/~mwh/se-tutorial/symbolic-exec.pdf> 
- A Survey of Symbolic Execution Techniques: <https://arxiv.org/pdf/1610.00502.pdf>
- Circuit IR Compilers and Tools based on LLVM and MLIR: <https://github.com/llvm/circt> and <https://github.com/llvm/circt/blob/master/docs/Charter.md>
- GCC Porting to New Hardware or Operating Systems: <https://gcc.gnu.org/onlinedocs/libstdc++/manual/internals.html>
- OSDI'20, Ansor: Generating High-Performance Tensor Programs for Deep Learning. RFC see: <https://discuss.tvm.apache.org/t/rfc-ansor-an-auto-scheduler-for-tvm-autotvm-v2-0/7005> and corresponding pull request: <https://github.com/apache/incubator-tvm/pull/5883> and <https://github.com/apache/incubator-tvm/pull/5962>
- [RFC] TensorIR: A schedulable IR for TVM: <https://discuss.tvm.apache.org/t/rfc-tensorir-a-schedulable-ir-for-tvm/7872>
- Hints and Principles for Computer System Design: <https://www.microsoft.com/en-us/research/publication/hints-and-principles-for-computer-system-design-3/>, 2020 version see [here](https://www.dropbox.com/sh/4cex542zznbjh7b/AADM59pqAb9YBy4eeT1uw0t8a?dl=0&preview=Hints+190+full.pdf) and 1993 ACM Turing Award lecture slides: <https://dl.acm.org/doi/pdf/10.1145/1283920.2159562>, Hints for computer system design <https://dl.acm.org/doi/10.1145/773379.806614>.
- Paper Review of "Hints On Computer System Design": <https://lethain.com/paper-review-of-hints-on-computer-system-design/>
- Great Principles of Computing: <http://greatprinciples.org>
- Unit Testing Each Operator(Kernel) in TensorFlow-Lite: <https://www.programmersought.com/article/6765234355/>
- PLDI'20, Understanding Memory and Thread Safety Practices and Issues in Real-World Rust Programs: <https://dl.acm.org/doi/abs/10.1145/3385412.3386036>
- Talks by Albert Cohen @PLISS'2019: Polyhedral Compilation as a Design Pattern for Compiler Construction, <https://pliss2019.github.io/albert_cohen_slides.pdf>
- Improving Compilation Time of C/C++ Projects: <https://interrupt.memfault.com/blog/improving-compilation-times-c-cpp-projects>
- HOW (AND HOW NOT) TO WRITE A GOOD SYSTEMS PAPER: <https://www.usenix.org/conferences/author-resources/how-and-how-not-write-good-systems-paper> & <https://www.usenix.org/legacy/publications/library/proceedings/dsl97/good_paper.html> & Course summary from Prof. Jianfeng Zhan: <http://prof.ict.ac.cn/DComputing/uploads/2013/DC_1_2_how_to_write_a_good_system_paper.pdf>
- The Art of the MetaObject Protocol: <https://ldbeth.sdf.org/The_Art_of_the_Metaobject_Protocol.pdf>
- StarPU: A Unified Runtime System for Heterogeneous Multicore Architectures: <https://starpu.gitlabpages.inria.fr/>
- AVX-512 Vector Neural Network Instructions (VNNI) - x86: <https://en.wikichip.org/wiki/x86/avx512_vnni>
- ISPASS'21 best paper nominee: Characterizing Massively Parallel Polymorphism, <https://drive.google.com/file/d/1suEa8mrMqCP1X2DcE1Ck9DK1qrPbbQ3v/view>; ASPLOS'21: Judging a Type by its Pointer: Optimizing GPU Virtual Function Calls; Runtime polymorphism has been supported in CUDA 11.2: <https://nvidia.github.io/libcudacxx/>
- EditorConfig helps maintain consistent coding styles for multiple developers working on the same project across various editors and IDEs: <https://editorconfig.org/>
- How the Boeing 737 Max Disaster Looks to a Software Developer: <https://spectrum.ieee.org/aerospace/aviation/how-the-boeing-737-max-disaster-looks-to-a-software-developer>
- On the Expressive Power of Programming Languages: <https://homepage.cs.uiowa.edu/~jgmorrs/eecs762f19/papers/felleisen.pdf>
- EuroMLSys'21, DISC: A Dynamic Shape Compiler for Machine Learning Workloads: <https://dl.acm.org/doi/10.1145/3437984.3458838> & [RFC] Dynamic shape for XLA with MLIR: <https://groups.google.com/a/tensorflow.org/g/mlir/c/_X48poNcbDI/m/jCC8BWIICQAJ>
- A Survey of Deep **Active Learning**: <https://arxiv.org/abs/2009.00236>
- DATE'21, Deep Neural Network Hardware Deployment Optimization via Advanced Active Learning: <http://www.cse.cuhk.edu.hk/~byu/papers/C113-DATE2021-TVM-AL.pdf>
- Gradual Type System: <https://blog.sigplan.org/2019/07/12/gradual-typing-theory-practice/>
- Null-References: the Billion Dollar Mistake, by Tony Hoare: <https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/>
- CPU Memory Model, tiny blog: <https://dl.acm.org/doi/10.1145/1353522.1353528>




**Fifteen nice and interesting blogs list:**

- Paul Graham Essays: <http://www.paulgraham.com/articles.html>
- Peter Krumins' blog: <https://catonmat.net>
- Fluent C++: <http://www.fluentcpp.com>
- Programming is terrible: <https://programmingisterrible.com>
- Evan Klitzke: <https://eklitzke.org>
- Brendan D. Gregg: <http://www.brendangregg.com/index.html>
- Herb Sutter on software development: <https://herbsutter.com>
- Eli Bendersky's website: <https://eli.thegreenplace.net>
- Martin Fowler: <https://martinfowler.com>
- The Clean Code  Blog: <http://blog.cleancoder.com>
- Joel On Software: <https://www.joelonsoftware.com>
- Coding Horror: <https://blog.codinghorror.com>
- null program: <https://nullprogram.com/index/>
- Julia Evans: <https://jvns.ca>
- Hack Noon: <https://hackernoon.com>




